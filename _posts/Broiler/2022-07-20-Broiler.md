---
layout: post
title:  "Broiler Virtualization Technology"
date:   2022-07-20 12:00:00 +0800
categories: [MMU]
excerpt: Virtualization.
tags:
  - HypV
---

![](/assets/PDB/BiscuitOS/kernel/IND00000L0.PNG)

#### 目录

> - [Broiler 项目简介](#A)
>
> - [Broiler 使用攻略](#B)
>
> - [Broiler 内存虚拟化](#C)
>
>   - [DDR 模拟]()
>
>   - [MMIO 模拟]()
>
> - [Broiler IO 端口虚拟化]()
> 
>   - [PIO 端口模拟](#K1)
>
>   - [同步 IO 模拟]()
>
>   - [异步 IO 模拟]()
>
> - [Broiler BIOS](#D)
>
> - [CPU 虚拟化]()
>
> - [中断虚拟化](#E)
>
>   - [PIC 8259A](#E0)
>
>   - [APIC: Local APIC and I/O APIC](#E1)
>
>   - [中断重要概念](#E2)
>
>   - [X86 中断虚拟化](#E3)
>
>   - [设备中断虚拟化](#E4)
>
> - [Broiler 设备虚拟化](#K)
>
>   - [PCI 设备模拟](#K2)
>
>   - [DMA 模拟]()
>
> - [virtio-blk 磁盘设备](#F2)
>
>   - [virtio-blk PCI 设备](#F8)
>
>   - [virtio-blk BAR0](#F3)
>
>   - [virtio-blk PIO/MMIO 模拟](#F9)
>
>   - [virtio-blk Virtqueue](#F4)
>
>   - [virtio-blk 初始化](#F7)
>
> - [Foodstuff Paradise](#P)
>
>   - [模拟一个 IO-BAR/MEM-BAR PCI 设备]()
>
>   - [模拟一个 INTX 中断的 PCI 设备]()
>
>   - [模拟一个 MSI 中断的 PCI 设备]()
>
>   - [模拟一个 MSIX 中断的 PCI 设备]()
>
>   - [模拟一个带 DMA/INTX 的 PCI 设备]()
>
>   - [模拟一个带 DMA/MSI 的 PCI 设备]()
>
>   - [模拟一个带 DMA/MSIX 的 PCI 设备]()
>
>   - [模拟一个 DMA 控制器外设]()
>
>   - [模拟一个 DDR 控制器外设]()
>
>   - [模拟一个 DDR 控制器 PCI 设备]()
>
>   - [模拟一个带 PIO 的外设]()
>
>   - [模拟一个同步 PIO]()
>
>   - [模拟一个异步 PIO]()
>
>   - [模拟一个同步 MMIO]()
>
>   - [模拟一个异步 MMIO]()
>
>   - [模拟一个中断触发器]()

######  🙂🙂🙂🙂🙂🙂🙂🙂🙂🙂🙂 捐赠一下吧 🙂🙂🙂🙂🙂🙂🙂🙂🙂🙂🙂

![BiscuitOS](/assets/PDB/BiscuitOS/kernel/HAB000036.jpg)

-------------------------------------------

<span id="A"></span>

![](/assets/PDB/HK/TH001699.JPEG)

#### Broiler 项目简介

![](/assets/PDB/HK/TH001699.png)对应的 PCI 设备

Broiler 是一个 X86 CPU 模拟器开源项目，皆在为开发者提供一套快速编译、架构简洁、运行高效的虚拟机底座方案。传统的 BiscuitOS 项目是基于 QEMU/KVM 组合构建的 Linux 发行版系统，新架构下的 Broiler 与 KVM 配合提供了 BiscuitOS 运行的虚拟化底座，另外 Broiler 也支持嵌套的虚拟化技术。Broiler 项目包含了一个精简的 BIOS、一套自定义的内存布局以及多种外设，并通过 virtio 协议提供了 virtio-blk 后端设备，与 Linux 的 virtio-blk 前段设备配合使用。结合以上特点，Broiler 致力于为开发者打造一套极简的虚拟化开发环境，以及提供一套最佳的 virtio 协议和 KVM 实践环境.

> [Broiler Github Repositories 链接](https://github.com/BiscuitOS/Broiler) 

![](/assets/PDB/HK/TH001700.png)

上图是 Broiler 项目使用 Intel VT-x 虚拟化技术模拟出来的 Broiler 定制 CPU，其 vendor_id 为 BiscuitOS，Model name 为 "Broiler@16th Spe Intel(R) @ 5.50Hz". Broiler 可支持的带 virtio 协议的 Linux 版本，目前不支持 AMD 的 CPU。

![](/assets/PDB/HK/TH001701.png)

Broiler 支持的物理地址总线域由 PCI 总线域、 DDR 域以及外设映射区域构成，Broiler 还支持 X86 的 IO 空间。Broiler 支持最小 256MiB 的 DDR，DDR 在物理地址总线低端的映射范围为 \[0x00000000, 0xC0000000), 高端的映射范围从 0x100000000 开始。Broiler 支持一条 PCI 总线，PCI 总线域映射的 MMIO 从 \[0xC0000000, 0x100000000), 这段区域也包括一些设备的映射区域，例如 Local APIC 的映射区域，这里都作为 MMIO。Broiler 支持的 IO 空间如上图，包括了 PCI Config 的 DATA 和 ADDR PORT，以及一些常见的外设端口. 更多细节描述可以参考[Broiler 内存管理](#C)章节.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="B"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000Q.jpg)

#### Broiler 使用攻略

![](/assets/PDB/HK/TH001702.png)

Broiler 项目已经适配多种场景，开发者可以在一台 Linux 发行版上直接部署使用 Broiler 项目，也可以基于 BiscuitOS 项目在 BiscuitOS 内部运行 Broiler, 甚至可以 Broiler 嵌套 Broiler 方式使用。开发者可以根据自身需求进行使用，默认推荐基于 BiscuitOS 进行 Broiler 的构建。具体参考如下:

> - [PlanA: Linux 发行版直接部署 Broiler 项目](#B1)
>
> - [PlanB: 基于 BiscuitOS 构建 Broiler 项目](#B2)
>
> - [PlanC: 构建基于 Broiler 项目的 BiscuitOS](#B3)
>
> - [PlanD: 部署 Broiler 嵌套 Broiler 项目(功能未开放)](#B4)

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="B1"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000F.jpg)

#### Linux 发行版直接部署 Broiler 项目

![](/assets/PDB/HK/TH001703.png)

Broiler 项目支持在 Linux 发行版上直接部署和运行 Linux 发行版，开发者可以自行准备带有 virtio 协议的 Linux 发行版镜像，也可以使用 Broiler 提供的 BiscuitOS 发行版. Broiler 项目基于 Intel 的硬件进行构建，因此开发者需要确保其处理器是 Intel 的处理器，另外需要开发者将处理器的 VT-x 和 VT-d 功能打开，具体打开方法可以参考网上，另外开发者需要准备 Linux 发行版，默认推荐 Ubuntu20.04 或者 Ubuntu 18.04，Linux 发行版上需要提前安装 kvm 模块。该方案开发者只能源码调试 Broiler，对于内核、KVM 无法进行源码调试。在本方案中，使用 Broiler 项目在 Linux 发行版上直接运行一个虚拟机。本节以 Ubuntu20.04 和 BiscuitOS 发行版为例进行说明，开发者可以参考如下步骤进行部署:

{% highlight bash %}
# 确认系统已经打开 VT-x
lscpu | grep Virtualization

# 安装 kvm 模块
sudo apt install -y qemu-kvm

# 下载 Broiler 源码
git clone https://github.com/BiscuitOS/Broiler.git
cd Broiler/
{% endhighlight %}

![](/assets/PDB/HK/TH001704.png)

Broiler 源码如上图，其中 bios 是 BIOS 相关的源码; broiler 目录下 Broiler 虚拟化技术的核心，用于虚拟 CPU 各种组件; hw 目录下提供了 Broiler 支持的设备模拟 Demo; include 目录下包括各类型的头文件; lib 目录下提供了 Broiler 使用的各类库函数; virtio 目录下包括了 virtio 协议的核心代码，以及一些 virtio 设备后端的实现. main.c 文件为 Broiler 的入口函数，Makefile 为编译项目的配置文件，RunBroiler.sh 用于启动 Broiler 的快速脚本，COPYING 为 Broiler 使用的 GPL 说明文件，README.md 为项目的简易说明文档. 接下来编译 Broiler 项目:

{% highlight bash %}
# 清除上次编译残留
make clean
# 编译 Broiler
make
{% endhighlight %}

编译完成之后会在当前目录下生成 BiscuitOS_Broiler 可执行文件，那么接下来对启动参数进行说明:

{% highlight bash %}
./BiscuitOS-Broiler --kernel linux-5.10-bzImage \
		    --rootfs BiscuitOS.img \
		    --memory 256 \
		    --cpu 2 \
		    --cmdline "noapic noacpi pci=conf1 reboot=k panic=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 root=/dev/vda rw rootfstype=ext4 console=ttyS0 loglevel=8"
{% endhighlight %}

"--kernel" 参数指向内核镜像所在的路径，"--rootfs" 参数指向了 ROOTFS 所在的路径，"--memory" 参数指明 Broiler 启动的虚拟机内存大小，单位为 MiB，"--cpu" 参数指明 Broiler 启动虚拟机的 CPU 数量, "--cmdline" 参数指明 Broiler 启动的虚拟机内核使用的 cmdline. 开发者可以自定义修改这些参数，默认使用的 kernel 和 rootfs 可以通过如下命令进行下载:

{% highlight bash %}
# Download rootfs and Image
git clone https://gitee.com/BiscuitOS_team/broiler-image-rep.git
cd broiler-image-rep/

# 使用镜像
cd Broiler/
./BiscuitOS-Broiler --kernel */broiler-image-rep/linux-5.10-bzImage \
                    --rootfs */broiler-image-rep/BiscuitOS.img \
                    --memory 256 \
                    --cpu 2 \
                    --cmdline "noapic noacpi pci=conf1 reboot=k panic=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 root=/dev/vda rw rootfstype=ext4 console=ttyS0 loglevel=8"
{% endhighlight %}

![](/assets/PDB/HK/TH001700.png)

上图便是成功使用 Broiler 启动了一个虚拟机，接下来开发者可以使用 Broiler 源码研究其实现，也可以将内核镜像和 ROOTFS 替换成自定义的镜像，更多的可能留给开发者自己.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="B2"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000T.jpg)

#### 基于 BiscuitOS 构建 Broiler 项目

![](/assets/PDB/HK/TH001705.png)

Broiler 项目支持在 BiscuitOS 上部署实践，其原理是现在 Linux 发行版上启动一个 BiscuitOS 虚拟机，然后再在内部启动 Broiler，这样做的优势是隔离性比较好，其次是这个方案可以对内核、KVM 和 Broiler 源码都进行修改调试。该方案同理也需要准备一台已经打开 VT-x/VT-d 的 Linux 发行版，并且已经安装 KVM 模块。接着需要部署 BiscuitOS，然后在 BiscuitOS 开发环境中部署 Broiler，看着过程很负责，其实推荐开发者使用这个方案，方案一定部署会因 BiscuitOS 带来很多开发效益的提升。开发者可以参考如下步骤进行部署使用, 首先部署一个 Linux 5.10 的环境:

> [BiscuitOS Linux 5.10 X86 开发环境部署](/blog/Linux-5.x-x86_64-Usermanual/)

部署完 BiscuitOS Linux 5.10 X86 开发环境之后，接下来部署 Broiler 源码，使用如下命令:

{% highlight bash %}
# 切换到 BiscuitOS 目录
cd BiscuitOS
make linux-5.10-x86_64_defconfig
make menuconfig

  [*] Package --->
      [*] KVM --->
          [*] BiscuitOS hyperv: Broiler

# 保存配置并使配置生效
make

# 进入 Broiler 目录
cd output/linux-5.10-x86_64/package/BiscuitOS-Broiler-default/
{% endhighlight %}

![](/assets/PDB/HK/TH001706.png)
![](/assets/PDB/HK/TH001707.png)
![](/assets/PDB/HK/TH001708.png)
![](/assets/PDB/HK/TH001704.png)

Broiler 源码如上图，其中 bios 是 BIOS 相关的源码; broiler 目录下 Broiler 虚拟化技术的核心，用于虚拟 CPU 各种组件; hw 目录下提供了 Broiler 支持的设备模拟 Demo; include 目录下包括各类型的头文件; lib 目录下提供了 Broiler 使用的各类库函数; virtio 目录下包括了 virtio 协议的核心代码，以及一些 virtio 设备后端的实现. main.c 文件为 Broiler 的入口函数，Makefile 为编译项目的配置文件，RunBroiler.sh 用于启动 Broiler 的快速脚本，COPYING 为 Broiler 使用的 GPL 说明文件，README.md 为项目的简易说明文档. 接下来编译 Broiler 项目:

{% highlight bash %}
# 清除上次编译残留
make clean
# 编译 Broiler
make
# 更新 ROOTFS
make install
make pack
{% endhighlight %}

编译完成之后会在当前目录下生成 BiscuitOS-Broiler-default 可执行文件，Broiler 运行的参数放在 RunBroiler.sh 文件里，其内容如下:

{% highlight bash %}
#!/bin/ash
# SPDX-License-Identifier: GPL-2.0-only

BiscuitOS-Broiler-default --kernel /mnt/Freeze/BiscuitOS-Broiler/bzImage \
                          --rootfs /mnt/Freeze/BiscuitOS-Broiler/BiscuitOS.img \
                          --memory 256 \
                          --cpu 2 \
                          --cmdline "noapic noacpi pci=conf1 reboot=k panic=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 root=/dev/vda rw rootfstype=ext4 console=ttyS0 loglevel=8"
{% endhighlight %}

"--kernel" 参数指向内核镜像所在的路径，"--rootfs" 参数指向了 ROOTFS 所在的路径，"--memory" 参数指明 Broiler 启动的虚拟机内存大小，单位为 MiB，"--cpu" 参数指明 Broiler 启动虚拟机的 CPU 数量, "--cmdline" 参数指明 Broiler 启动的虚拟机内核使用的 cmdline. 开发者可以自定义修改这些参数, 另外 Broiler 启动虚拟机使用的内核和 ROOTFS 已经打包到 BiscuitOS 的 ROOTFS 中，接下来直接使用如下命令进行实践:

{% highlight bash %}
# 运行 BiscuitOS
make run

# 进入 BiscuitOS 之后启动 Broiler
RunBroiler
{% endhighlight %}

![](/assets/PDB/HK/TH001700.png)

上图便是成功使用 Broiler 启动了一个虚拟机。开发者也可能遇到 Broiler 启动不了的问题，原因是找不到 /dev/kvm, 那么这个需要打开内核的宏: CONFIG_KVM 和 CONFIG_KVM_INTEL 宏。开发者可以修改内核源码和 KVM 源码，修改完毕之后，在 BiscuitOS-Broiler-default 目录下执行如下代码更新内核和 KVM:

{% highlight bash %}
# 编译内核和 KVM
make kernel

# 将内核和 KVM 更新到 ROOTFS
make install
make pack

# 运行 BiscuitOS
make run

# 进入 BiscuitOS 之后启动 Broiler
RunBroiler
{% endhighlight %}

通过上面的流程，开发者可以根据需求修改内核源码和 KVM 源码，并通过简单命令就可以更新到 ROOTFS 进行实践，那么接下来更多的可能留给开发者自己.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="B3"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000I.jpg)

#### 构建基于 Broiler 项目的 BiscuitOS

![](/assets/PDB/HK/TH001709.png)

传统的 BiscuitOS 项目是基于 KVM 与 QEMU 进行搭建的，其优点是虚拟化功能齐全，调试工具和手段丰富，但缺点就是 QEMU 过于复杂和冗余，而且移植难度大，编译慢和运行相对慢的特点。如果开发者只是纯粹的使用 QEMU 启动一个 BiscuitOS 来调试内核，那么可以考虑使用 Broiler 替换 QEMU，这样的优点是可以大大加快部署和编译的速度，加快内核启动的速度。同理该方案同理也需要准备一台已经>打开 VT-x/VT-d 的 Linux 发行版，并且已经安装 KVM 模块。那么接下来介绍部署一个 Broiler 的 Linux 5.10 X86 开发环境, 开发者参考如下步骤:

> [BiscuitOS Linux 5.10 X86 开发环境部署](/blog/Linux-5.x-x86_64-Usermanual/)

部署完 BiscuitOS Linux 5.10 X86 开发环境之后，接下来部署 Broiler 源码，使用如下命令:

{% highlight bash %}
# 切换到 BiscuitOS 目录
cd BiscuitOS
linux-5.10-x86_64-Broiler_defconfig
# 保存配置并使配置生效
make

# 进入 linux 5.10 目录
cd output/linux-5.10-x86_64/
{% endhighlight %}

![](/assets/PDB/HK/TH001710.png)

部署成功之后，可以看到 Broiler-system 目录，该目录即 BiscuitOS 使用的虚拟化底座，进入 Broiler-system 查看其源码:

![](/assets/PDB/HK/TH001704.png)

Broiler 源码如上图，其中 bios 是 BIOS 相关的源码; broiler 目录下 Broiler 虚拟化技术的核心，用于虚拟 CPU 各种组件; hw 目录下提供了 Broiler 支持的设备模拟 Demo; include 目录下包括各类型的头文件; lib 目录下提供了 Broiler 使用的各类库函数; virtio 目录下包括了 virtio 协议的核心代码，以及一些 virtio 设备后端的实现. main.c 文件为 Broiler 的入口函数，Makefile 为编译项目的配置文件，RunBroiler.sh 用于启动 Broiler 的快速脚本，COPYING 为 Broiler 使用的 GPL 说明文件，README.md 为项目的简易说明文档. 那么接下来查看 BiscuitOS 的启动参数，即 Broiler 的启动参数，其位于 linux 5.10 目录下的 RunBiscuitOS.sh:

{% highlight bash %}
# ROOTFS 镜像大小
ROOTFS_SIZE=150
# 数据盘大小
FREEZE_SIZE=512
# 内存大小
RAM_SIZE=512

...

do_running()
{
	....

        sudo ${BROILER} \
                --kernel ${LINUX_DIR}/x86/boot/bzImage \
                --rootfs ${ROOT}/BiscuitOS.img \
                --memory ${RAM_SIZE} \
                --cpu 2 \
                --cmdline "${CMDLINE}"
}
{% endhighlight %}

"--kernel" 参数指向内核镜像所在的路径，"--rootfs" 参数指向了 ROOTFS 所在的路径，"--memory" 参数指明 Broiler 启动的虚拟机内存大小，单位为 MiB，"--cpu" 参数指明 Broiler 启动虚拟机的 CPU 数量, "--cmdline" 参数指明 Broiler 启动的虚拟机内核使用的 cmdline. 接下来直接使用如下命令进行实践:

{% highlight bash %}
cd BiscuitOS/cd output/linux-5.10-x86_64/
./RunBiscuitOS.sh
{% endhighlight %}

![](/assets/PDB/HK/TH001700.png)

上图便是成功使用 Broiler 启动 BiscuitOS，开发者可以修改各种源码，然后在 BiscuitOS 进行实践，那么接下来更多的可能留给开发者自己.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="C"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000M.jpg)

#### Broielr 内存虚拟化

![](/assets/PDB/HK/TH001481.png)

在 Intel X86 架构中，系统物理地址总线构成的空间称为**存储域**，其主要由三部分组成，一部分是 DDR 控制器管理的 DDR 域，另外一部分是 PCI 总线域映射到存储域的 PCI 总线地址，最后一部分是设备内部存储空间映射到存储域的区域，这里统一将后者统称为 MMIO。Intel X86 架构也通过 Host PCI 主桥维护一颗 PCI 总线，该 PCI 总线构成的空间称为**PCI 总线域**。

![](/assets/PDB/HK/TH001695.png)

在 X86 架构中，存储域的空间长度和 PCI 总线域的长度是相同的，并且 DDR 域的地址可以映射到存储域，也可以映射到 PCI 总线域，同理 PCI 域的地址也可以映射到存储域，切该地址在存储域上称为 PCI 总线地址。

![](/assets/PDB/HK/TH001711.png)

在 Broiler 模拟的 X86 架构中，DDR 映射范围被划分做两段，第一段是 \[0x00000000, 0xC0000000), 大小为 2Gig 内存, 第二段从 0x100000000 开始. PCI 域映射到存储域的范围是 \[0xC0000000, 0x100000000), 该区域包括了 PCI 总线地址，同时也包括了其他外设存储空间映射的区域，例如 Local APIC 映射的 MMIO 区域.

![](/assets/PDB/HK/TH001712.png)

DDR 内存控制器可以看到完整的 DDR 域空间，DDR 域空间一般分作 3 类，第一类是直接映射到系统存储域的区域，第二类是重映射到系统存储域的区域，最后一类是系统进入 SMM 模式才可以访问的区域。在 Broiler 模拟的 X86 架构中，低于 2Gig 的 DDR 物理内存直接映射到系统存储域的低 2Gig 区域; 超过 4Gig 的 DDR 物理内存直接映射到系统存储域 4Gig 开始处; DDR 2Gig 到 3Gig 部分则通过重映射机制映射到了系统存储域 Reclaim Base 开始的地方，Reclaim Base 的地址正好是 DDR 4G 之后的长度。映射完毕之后，系统存储域 2Gig 到 4Gig 的部分预留给了 PCI 总线域映射的 MMIO，如果 PCI 总线域映射的范围超过了 2Gig，那么继续映射到 TOUUD BASE 之后，该地址是 DDR 重映射区域结束的地址.

![](/assets/PDB/HK/TH001713.png)

上图是一个 Broiler 运行的 4Gig 虚拟机，通过 "/proc/iomem" 接口可以看到系统存储域的布局，可以看到 System RAM 占用的范围是 \[0x00100000, 0xbfffffff], 以及 \[0x100000000, 0x13fffffff]. 另外可以看到 PCI 的 MMIO 从 0xC2000000 开始. 这个布局符合 Broiler 的规划.

![](/assets/PDB/HK/TH001714.png)

上图是一个 Broiler 运行的 2Gig 虚拟机，通过 "/proc/iomem" 接口可以看到系统存储域的布局，可以看到 System RAM 占用的范围是 \[0x00100000, 0x7fffffff]. 另外可以看到 PCI 的 MMIO 从 0xC2000000 开始，这个布局符合 Broiler 的规划.

![](/assets/PDB/HK/TH001715.png)

X86 架构中存在存储域和 IO 地址空间，IO 地址空间用于映射外设的寄存器，并通过 IN/OUT 指令进行访问，Broiler 同样模拟了一系列的 IO 端口，这些端口中比较常用的是 PCI conf1 的 ADDR 和 DATA 端口，系统通过两个端口访问 PCI 设备的配置空间。

![](/assets/PDB/HK/TH001717.png)

Broiler 使用 struct broiler_memory_region 数据结构描述一段 DDR 内存区域，以及这段 DDR 内存映射到 Guest OS 存储域的信息。其 guest_phys_addr 成员记录了这段 DDR 区域映射到 Guest OS 存储域的物理地址，这里可以称为 GPA; host_addr 成员记录了这段 DDR 区域在 Host 端的虚拟地址，也就是 HVA; size 成员指明了 DDR 区域映射到 Guest OS 存储域的长度.

![](/assets/PDB/HK/TH001716.png)

系统内可以同时存在多块 DDR 区域，那么就存在多个 struct broiler_memory_region 变量，Broiler 使用一颗区间树(由红黑树改造而来)，将所有的 DDR 区域按其在 Guest OS 存储域的地址 GPA 从小到大的插入到区间树里，那么 Broiler 可以使用一个 GPA 地址找到对应的 struct broiler_memory_region 数据结构，进而找到 HVA 地址。Broiler 提供了一系列接口辅助地址的转换:

{% highlight bash %}
# GPA(实施模式的物理地址) 转换为 HVA
static inline void *gpa_real_to_hva(struct broiler *broiler, u16 selector, u16 offset)
# GPA(保护模式的物理地址) 转换为 HVA
static inline void *gpa_flat_to_hva(struct broiler *broiler, u64 offset)
# GPA 转换成 HVA
void *gpa_to_hva(struct broiler *broiler, u64 offset)
{% endhighlight %}

![](/assets/PDB/HK/TH001718.png)

Broiler 使用 struct mmio_mapping 数据结构描述 Guest OS 存储域上的一段 MMIO，与内存管理类似，其使用一颗区间树 mmio_tree 管理所有 MMIO 区间，并使用 MMIO 区域的范围作为插入的条件，那么按先序遍历区间树的时候，MMIO 区间起始地址小的会被先遍历到。另外数据结构还包括了 mmio_fn 成员，该程序指向的函数用于处理虚拟机因为访问 MMIO 导致 VM_EXIT 时对 MMIO 区域进行读写模拟。Broiler 也使用 struct mmio_mapping 数据结构描述 Guest OS IO 空间的一段 IO 端口，其通过 pio_tree 区间树进行维护，其通过 IO 端口的区间范围插入到区间树，同理当 Guest OS 范围 IO 端口时，虚拟机也会 VM_EXIT 退出，退出之后 Broiler 就在 pio_tree 区间树中查找对应的 struct mmio_mapping, 然后找到其 mmio_fn 指向的函数，然后进行 IO 端口的读写模拟. Broiler 提供了一系列的接口辅助地址的转换:

{% highlight bash %}
# IO 端口的读操作 (Guest to Host)
static inline u8 ioport_read8(u8 *data)
static inline u16 ioport_read16(u16 *data)
static inline u32 ioport_read32(u32 *data)

# IO 端口的写操作 (Host to Guest)
static inline void ioport_write8(u8 *data, u8 value)
static inline void ioport_write16(u16 *data, u16 value)
static inline void ioport_write32(u32 *data, u32 value)
{% endhighlight %}

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="D"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000B.jpg)

#### Broiler BIOS

Broiler 提供了一个简易的 BIOS，何为简易? 这得从 BIOS 的作用说起，BIOS 的作用是初始化硬件，将硬件初始化到一个已知状态，然后提供中断向量表和 E820 表，然后部分 BDA 和 EBDA 数据，那么初始化阶段 BIOS 的使命就可以结束，那么可以不真正在虚拟机内运行 BIOS，而是直接将特定的数据直接写到内存的指定位置上即可，然后提供一些内核需要调用的 BIOS IVT 中断，最后提供一份 E820 表即可.

![](/assets/PDB/HK/TH001719.png)

在系统的物理地址总线空间，也就是存储域的前 1MiB 空间，原本是映射了 DDR 的物理内存，但这段物理内存预留给 Legacy BIOS 使用，那么操作系统不再直接使用这段物理内存。另外 BIOS 原先存储在 ROM 里，然后系统访问 ROM 的速度远比 RAM 的慢，那么为了加快速度就把 BIOS 的内容由 ROM 拷贝到 RAM，并放置在低 1MiB 物理内存。BIOS 正常运行时会将低 1MiB 区域分作不同的用途，其中 \[0x00000000, 0x00000400) 区域用于存放 BIOS 中断向量表; \[0x00000400, 0x00000500) 区域用于存储 BIOS 的 BDA 数据区, \[0x00005000, 0x0009FC00) 区域作为可动态支配的区域; \[0x0009FC00, 0x000A0000) 区域则存放 BIOS EBDA 数据. \[0x000A0000, 0x000C8000) 区域被 Legacy VIDEO RAM/ROM 占用，作为特殊用途使用. 值得注意的是 E820 位于 EBDA 开始处，并往下延伸.

![](/assets/PDB/HK/TH001720.png)

内核在启动过程中，主要使用了 BIOS 中断向量表提供的 Int15 中断和 Int10 中断，其中 Int15 中断用于获得 E820 表，其代码实现如上图. Int10 中断则是字符输出相关的中断，这里不做介绍，具体细节可以参看源码 bios/ 目录下内容.

-------------------------------------------

<span id="K"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000D.jpg)

#### Broiler 设备虚拟化

设备虚拟化是系统虚拟化软件使用软件的方式呈现给 Guest OS 硬件设备的逻辑，其先后经历了完全虚拟化、半虚拟化，以及硬件辅助虚拟化，包括将硬件直接透彻 (Passthrough) 给虚拟机，以及将一个硬件从硬件层面虚拟成多个硬件子系统，每个子系统分别透传给虚拟机等。Broiler 目前支持设备完全虚拟化和半虚拟化方案，其中半虚拟化方案就是标准 Virtio 协议。

![](/assets/PDB/HK/TH001722.png)

Broiler 最先支持的是设备全虚拟化方案，该方案按照硬件设备规范，完完整整地模拟硬件设备的逻辑. 当虚拟机运行的时候需要访问 I/O，那么会导致虚拟机停止运行并退出 (VM_EXIT), 内核的 KVM 模块最先捕获到虚拟机的退出，然后获知虚拟机退出的原因是访问 I/O, 那么 KVM 模块无法模拟这个硬件过程，那么将模拟的请求发送给用户空间的 Broiler，Broiler 在获知虚拟机退出的原因是访问 IO，那么 Broiler 进一步确认是访问哪个 IO，以及 Broiler 是否对该 IO 进行模拟，如果有那么 Broiler 运行相关的硬件模拟逻辑，如果需要返回数据，Broiler 将模拟产生的数据再次发送给内核 KVM，内核 KVM 组件收到硬件模拟完成的信息之后，通过 VM-Entry 一并数据发送给虚拟机，虚拟机恢复运行并获得所需的 IO 处理结果，那么虚拟机继续运行. 反之如果 Broiler 没有模拟相应的硬件，那么会直接通知内核 KVM 组件，KVM 组件将异常的结果一并返回给虚拟机，虚拟机再次运行时就会获得 IO 异常的信息.

![](/assets/PDB/HK/TH001723.png)

在全模拟方案中，Guest OS 只要访问 I/O 就会导致虚拟机退出，然后内核 KVM 处理不了就转到用户空间让 Broiler 进行处理，这大大降低了 I/O 性能。那为什么不直接在内核中完成设备的模拟动作呢? 在有的场景下，设备虚拟化更适合在内核空间进行，比如典型的中断虚拟化芯片的模拟，但有些设备模拟很复杂，如果放在内核中实现，除了增加内核的复杂度，也容易带来安全问题，于是提出了一种折中的 **Vhost 方案**，将设备模拟的数据处理面搬到内核，设备控制面还保留在用户空间。该方案从 Guest 到 KVM 的交互只有一次用户态的切换以及数据拷贝，并且 Guest 到 Host NIC 之间的通信是比较好的。

![](/assets/PDB/HK/TH001724.png)

对于软件方式的设备模拟来讲，完全没必要完全模拟硬件行为，而是制定一个更高效、简洁地适用于 Guest 驱动和设备交互的方式，于是提出了半虚拟化的概念。在虚拟机中，可以通过 Hypervisor 模拟 e1000 网卡，这个经典的网卡在各种客户 OS 都会提供 inbox 驱动，所以兼容性上来看是个不错的选择，但 e1000 包含了复杂的 IO 端口、寄存器和缓存配置，虚拟机每次收发包都会引起更多的 IO 和 MMIO 操作，使得虚拟机陷出，最终导致网络性能不佳。为了解决这个问题, IBM 在 2005 年提出了 virtio 协议，虚拟机中的半虚拟化前段驱动和主机上的后端设备简单使用 virtqueue 共享队列交换数据，大大减少了 e1000 模拟时复杂的 IO 操作，从而较大程度提升了虚拟网络性能.

![](/assets/PDB/HK/TH001725.png)

virtio 是一种 I/O 半虚拟化解决方案，是一套通用的 I/O 设备虚拟化的框架，也是对半虚拟化 Hypervisor 中的一组通用 I/O 设备的抽象。提供了一套上层应用程序与各 Hypervisor 虚拟化设备之间的通信框架，减少跨平台所带来的兼容性问题，大大提高了驱动程序的开发效率. Broiler 目前支持 virtio 协议的模拟设备包括: virtio-blk。

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-----------------------------------------------

###### <span id="K1">PIO 端口模拟</span>

![](/assets/PDB/HK/TH001745.png)

Linux 将地址空间分为了存储域空间和 IO 空间，CPU 可以直接通过指针引用来访问存储域空间，而 IO 空间则需要使用 IN/OUT 指令进行访问。IO 空间包含了很多的 IO 端口(Port), IO 端口是接口电路中 CPU 直接访问的寄存器地址。CPU 通过这些端口向接口电路中的寄存器发送命令，读取和传送数据. 上图是 Broiler 支持的 IO 端口, 比如常见的 PCI 配置空间的数据和地址寄存器、定时器寄存器、键盘控制器寄存器等。

![](/assets/PDB/HK/TH001746.png)

该源码为 Broiler 项目 hw/ 目录下的 BiscuitOS-pio-base.c 文件，该文件用于展示如何在 Broiler 模拟一个 PIO 端口。案例代码中模拟的端口起始地址为 0x6800, 长度为 16 个字节，这段区域中包含了 4 个寄存器，第一个是 SLOT_NUM 寄存器，用于维护 Slot 的数量; 第二个是 SLOT_SEL 寄存器，用于维护当前使用的 Slot 号; 第三个是 MIN_FREQ 寄存器，用于维护最小频率值; 最后一个是 MAX_FREQ 寄存器，用于维护最大频率值. 在 Broiler 初始化过程中需要进行一定的逻辑向系统模拟 PIO 硬件，例如案例 71 行调用 broiler_register_pio() 函数向 Broiler 平台模拟一个新的 PIO，其参数二和三指明了 PORT 的范围，以及 BiscuitOS_pio_callback() 函数用于模拟具体的 IO. 当 Broiler 需要移除 IO 端口模拟，可以使用 82 行的 broiler_deregister_pio() 函数，只需给出需要移除的端口号. 最后一起来看看 PIO 模拟 IN/OUT 指令的过程. BiscuitOS_pio_callback() 函数 37-47 行模拟了 OUT 指令，Broiler 使用 ioport_read32() 函数读取 Guest OS 向端口写入的内容; 函数 50-62 行模拟 IN 指令，Broiler 使用 ioport_write32() 函数向 Guest OS 的端口吐出需要读取的数据. 由于 Broiler 模拟 PIO 硬件还不够，需要 Guest OS 内部对 PIO 资源进行注册并使用，这里通过 BiscuitOS 项目提供的驱动介绍 Guest OS 内部如何使用 PIO，其可以通过 BiscuitOS 项目进行部署，部署逻辑如下:

{% highlight bash %}
# 切换到 BiscuitOS 目录
cd BiscuitOS
make linux-5.10-x86_64_defconfig
make menuconfig

  [*] Package --->
      [*] PIO: Programming Input/Output Model --->
          [*] PIO Driver for Broiler

# 保存配置并使配置生效
make

# 进入 Broiler 目录
cd output/linux-5.10-x86_64/package/BiscuitOS-Broiler-pio-default/
# 下载源码
make download
# 编译并运行源码
make
make install
make pack
make run
{% endhighlight %}

![](/assets/PDB/HK/TH001747.png)
![](/assets/PDB/HK/TH001748.png)
![](/assets/PDB/HK/TH001749.png)
![](/assets/PDB/HK/TH001750.png)

> [BiscuitOS-Broiler-pio-default Gitee @link](https://gitee.com/BiscuitOS_team/HardStack/tree/Gitee/Memory-Allocator/PIO/BiscuitOS-Broiler-pio)

BiscuitOS-Broiler-pio 驱动运行在 Guest OS 内部，其主要任务是将 Broiler 模拟的 PIO 注册到系统 IO 资源总线上，接着将 IO 端口映射到内存，并通过 Linux 提供的接口对四个寄存器进行访问。驱动在 24-29 行定义了新端口的资源描述，并将端口的名字设置为 "Broiler PIO", 驱动接着在 36 行调用 request_resource() 函数将 Broiler_pio_res 资源添加到系统 IO 空间，接着驱动在 40 行调用 ioport_map() 函数将 BISCUITOS_PIO_PORT 端口映射到存储域，并从 47-54 行调用 ioread32() 和 iowrite32() 函数对 IO 端口进行读写操作。接下来查看其基于 Broiler 在 BiscuitOS 中运行的情况:

![](/assets/PDB/HK/TH001751.png)

Broiler 版的 BiscuitOS 启动之后，加载驱动可以看到 log 显示了一些端口的操作，与 Broiler 模拟 PIO 行为一致，那么此时通过 /proc/ioports 查看 IO 空间的布局，此时看到 0x6800-0x6810 区域是 Broiler PIO 端口, 至此一次完整的 PIO 模拟实践完成，那么接下来分析 PIO 模拟的调用栈:

![](/assets/PDB/HK/TH001752.png)

Guest OS 对 PIO 发起的 IO 读操作，其会导致虚拟机 VM-EXIT, KVM 捕获到退出原因为 EXIT_REASON_IO_INSTRUCTION, 那么 KVM 通过 handle_io() 函数对 IO 读操作进行模拟，由于 PIO 的内容不是 In-kernel 的设备，那么 KVM 无法处理 IO 模拟，那么这个时候 KVM 将 IO 需要模拟的数据放到了 kvm_run 数据结构体中，其包含了 IO 端口号、读取数据的长度以及退出的原因为 KVM_EXIT_IO. KVM 将模拟 IO 任务转让给 Broiler 进行处理，Broiler 此时发现虚拟机因为 KVM_EXIT_IO 退出了，那么其在 pio_tree 红黑树中找到 IO 端口维护的模拟函数，对于 Broiler PIO 使用 BiscuitOS_pio_callback() 函数进行 IO 模拟。当 Broiler 模拟好 IO 数据之后，将其存储在 kvm_run 的 mmio_data 变量里，最后再次调用 KVM_RUN 进入到 KVM 中; KVM 收到 KVM_RUN IOCTL 之后，再次 VM_ENTRY 运行虚拟机，虚拟机运行之后继续执行对 PIO 的 IN 指令，此时 AX 寄存器里已经包含读到的 IO 模拟数据. 

![](/assets/PDB/HK/TH001753.png)

Guest OS 对 PIO 发起的 IO 写操作，其会导致虚拟机 VM-EXIT，KVM 捕获退出原因为 EXIT_REASON_IO_INSTRUCTION，那么 KVM 通过 handle_io() 函数对 IO 写操作进行模拟，由于 Broiler PIO 的内容不是 In-Kernel 的设备，那么 KVM 无法处理 IO 模拟，那么 KVM 将 IO 需要模拟的请求放到了 kvm_run 数据结构中，其包括了 IO 端口号、需要写入的数据、以及写入数据的长度，最后就是退出的原因填写为 KVM_EXIT_IO. KVM 将模拟 IO 任务转让给 Broiler 进行处理，Broiler 此时发现虚拟机因为 KVM_EXIT_IO 退出了，那么其在 pio_tree 红黑树中找到 IO 端口维护的模拟函数，Broiler PIO 使用 BiscuitOS_pio_callback() 函数模拟 IO 写操作。当 Broiler 模拟好 IO 之后调用 KVM_RUN 进入到 KVM 中; KVM 收到 KVM_RUN IOCTL 之后，再次 VM_ENTRY 运行虚拟机，此时虚拟机继续执行 Broiler PIO 写操作并完成.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="F2"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000L.jpg)

#### Virtio-blk 磁盘设备

virtio-blk 磁盘设备是使用 virtio 机制为 Guest OS 提供的一个高性能块设备 I/O 虚拟化的方法，其由 Guest OS 的前端驱动(Front-driver)和 Broiler 提供的后端驱动(Backed-driver) 组成，中间通过 vring 进行协商，在讲解 virtio-blk 之前先了解一下 Linux 块设备架构.

![](/assets/PDB/HK/TH001726.png)

在 Linux 中驱动对块设备的输入或输出 (I/O) 操作，都会向块设备发出一个请求，在驱动中使用 request 结构体进行描述。但对于一些磁盘设备而言请求速度很慢，这时内核就提供一种队列的机制把这些 IO 请求添加到队列中，这个队列就是请求队列，在驱动中使用 request_queue 结构体。在向块设备提交这些请求前内核会先执行请求的合并和排序预操作，以提高访问的效率，然后再由内核中的 I/O 调度子系统负责提交 I/O 请求，调度程序将资源分配给系统中的所有挂起的 I/O 请求，其工作是管理块设备的请求队列，决定队列中的请求的排列顺序以及什么时候发起请求到设备. 接着由通用块层 (Generia Block layer) 负责维持一个 I/O 请求在上层文件系统域底层物理磁盘之间的关系。在通用块层中，通常用一个 bio 结构体对应一个 I/O 请求. 块设备硬件对数据处理的基本单位称为扇区(Sectors), 一个扇区的大小为 512Bytes, Linux 制定对内核或文件系统数据处理的基本单位称之为块(Blocks),  通常一个块由一个或多个扇区构成.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-----------------------------------------------

###### <span id="F8">virtio-blk PCI 设备</span>

![](/assets/PDB/HK/TH001733.png)

virtio-blk 磁盘前端设备在 Guest OS 内存呈现为一个 PCI 设备, BDF 号为 00:00.0, 其包含三个 BAR，其中 BAR0 是一个 IO-BAR，其在 IO 空间的范围是 0x6200 到 0x62ff 的多个端口，BAR0 里包含了 virtio-blk 设备状态、VQ、Kick 、MSI 中断配置和磁盘相关的配置寄存器; BAR1 为一个 MM-BAR, 其映射在系统地址空间的范围是 \[0xc2000000, 0xc2000100), BAR 里的内容与 BAR0 一致; BAR2 为一个 MM-BAR，其映射在系统地址空间的范围是 \[0xc2000400, 0xc2000800), BAR 里的内容为 MSI 中断表相关的内容.

![](/assets/PDB/HK/TH001736.png)

Broiler 对 virtio-blk 对于的 PCI 设备配置空间进行模拟，其中包括为 IO-BAR 分配 IO 端口，为 MEM-BAR 分配 MMIO 地址，另外还包含了 PCI 设备 256 字节的配置空间内容的模拟。Broiler 还为每个 BAR 的地址访问进行模拟.

###### <span id="F3">virtio-blk BAR0</span>

![](/assets/PDB/HK/TH001731.png)

上图是 virtio-blk 磁盘对应前端设备看到的 PCI BAR0 bitmap，每当前端设备访问 BAR0 时会让虚拟机 VM-EXIT 退出到内核 KVM，KVM 处理不了让 Broiler 继续处理，Broiler 对BAR0 进行模拟，当 Broiler 模拟完毕之后将数据发送给 KVM，然后 KVM 在 VM-Entry 将数据传递给 Guest OS。那么回到 BAR0 本身，各字段的含义如下:

###### 0x00 - 0x03: 后端设备支持的磁盘特性
###### 0x04 - 0x07: 前端设备支持的磁盘特性

![](/assets/PDB/HK/TH001732.png)

前后端支持的特性如上图，前后端在交互过程中会确认各种所支持的磁盘特性，然后找出最小交集，最小交集就是该 virtio-blk 设备的磁盘特性。

###### 0x08 - 0x0B: Virtqueue 在 Guest 内的 GPA 地址

virtio-blk 磁盘前端设备负责在 Guest OS 内存申请一段内存，这段内存用于存储 Virtqueue 的 Desc-Ring、Avail-Ring 和 Used-Ring，然后将这段的物理内存 GPA 写入到该字段，后端设备通过该字段获得 Virtqueue 的 GPA 地址，进而获得 Virtqueue 对于的 HVA 地址，这样前后端就可以通过 Virtqueue 共享内存并交互数据.

###### 0x0C - 0x0D: Virtqueue Size

该字段用于描述 virtio-blk 使用 Virtqueue 的数量，该值由后端设备提供为只读。在 virtio-blk 磁盘中只使用一个 Virtqueue，因此该字段为 1.

###### 0x0E - 0x0F: Queue Select

该字段用于描述 virtio-blk 前端设备正在使用的 Virtqueue，在支持多 Virtqueue 设备的场景下，该字段用于描述前端设备正在使用哪个 Virtqueue。由于 virtio-blk 磁盘只使用一个 Virtqueu，那么该字段后端直接模拟为 0 即可，即第一个 Virtqueue.

###### 0x10 - 0x11: Kick

当 virtio-blk 磁盘前端设备准备好请求发我后端，再填充完 Avail-Ring 和 Desc-Ring 之后会向 Kick 字段进行写操作，该字段在 Broiler 里是一个特殊的区域，Broiler 会为该区域向 KVM 注册 ioeventfd，当因为 KVM_EXIT_IO 发生 VM-EXIT 之后，KVM 发现 IO 区域正好是 virtio-blk BAR0 的 kick，那么 KVM 会通过 ioveventfd 直接通知 Broiler，Broiler 在收到来自 KVM 的 ioeventfd 之后，Broiler 会触发处理磁盘请求的线程去处理请求，这个过程就实现了前端通知后端设备的逻辑链路.

###### 0x12: Device Status

该字段用于描述 virtio-blk 磁盘的状态，前后端设备都可以更新该字段。virtio-blk 磁盘可以根据 virtio 协议对该字段进行更新，目前支持的状态包括如下:

* ACKNOWLEDGE(Bit0): Guest OS 已经发现设备
* DRIVER(Bit1): Guest OS 加载驱动 Probe 驱动
* DRIVER_OK(Bit3): Guest OS 已经初始化好设备
* FAILED(BIT7): Guest OS 识别设备失败

###### 0x13: ISR Status

###### 0x14 - 0x15: Configuration Vector

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

---------------------------------------------------

###### <span id="F9">virtio-blk PIO/MMIO 模拟</span>

![](/assets/PDB/HK/TH001734.png)

virtio-blk 前端设备发起的 IO 读操作，其会导致虚拟机 VM-EXIT, KVM 捕获到退出原因为 EXIT_REASON_IO_INSTRUCTION, 那么 KVM 通过 handle_io() 函数对 IO 读操作进行模拟，由于 IO-BAR 的内容不是 In-kernel 的设备，那么 KVM 无法处理 IO 模拟，那么这个时候 KVM 将 IO 需要模拟的数据放到了 kvm_run 数据结构体中，其包含了 IO 端口号、读取数据的长度以及退出的原因为 KVM_EXIT_IO. KVM 将模拟 IO 任务转让给 Broiler 进行处理，Broiler 此时发现虚拟机因为 KVM_EXIT_IO 退出了，那么其在 pio_tree 红黑树中找到 IO 端口维护的模拟函数，对于 virtio-blk BAR0 的模拟由 virtio_pci_io_mmio_callback() 函数进行模拟，最后在 virtio_pci_data_in() 函数进行 IO 模拟。当 Broiler 模拟好 IO 数据之后，将其存储在 kvm_run 的 mmio_data 变量里，最后再次调用 KVM_RUN 进入到 KVM 中; KVM 收到 KVM_RUN IOCTL 之后，再次 VM_ENTRY 运行虚拟机，此时虚拟机继续将中断的 IO IN 指令继续执行，最后虚拟机从 IO-BAR 寄存器中读到值. 以上便是 KVM 与 Broiler 配合实现 virtio-blk IO-BAR IO 读模拟.

![](/assets/PDB/HK/TH001735.png)

virtio-blk 前端设备发起的 IO 写操作，其会导致虚拟机 VM-EXIT，KVM 捕获退出原因为 EXIT_REASON_IO_INSTRUCTION，那么 KVM 通过 handle_io() 函数对 IO 写操作进行模拟，由于 IO-BAR 的内容不是 In-Kernel 的设备，那么 KVM 无法处理 IO 模拟，那么 KVM 将 IO 需要模拟的请求放到了 kvm_run 数据结构中，其包括了 IO 端口号、需要写入的数据、以及写入数据的长度，最后就是退出的原因填写为 KVM_EXIT_IO. KVM 将模拟 IO 任务转让给 Broiler 进行处理，Broiler 此时发现虚拟机因为 KVM_EXIT_IO 退出了，那么其在 pio_tree 红黑树中找到 IO 端口维护的模拟函数，对于 virtio-blk BAR0 的模拟由 virtio_pci_io_mmio_callback() 函数进行模拟，最后在 virtio_pci_data_out() 函数进行 IO 模拟。当 Broiler 模拟好 IO 之后调用 KVM_RUN 进入到 KVM 中; KVM 收到 KVM_RUN IOCTL 之后，再次 VM_ENTRY 运行虚拟机，此时虚拟机完成了对 IO-BAR 的写操作. 以上便是 KVM 与 Broiler 配合实现 virtio-blk IO-BAR IO 写模拟.

![](/assets/PDB/HK/TH001737.png)

virtio-blk 前端设备有新的 IO 请求时，首先准备所需的数据，然后更新 Avail-Ring 的 avai_idx 的值，然后通过 BAR0 的 kick 寄存器写操作出发主动通知后端设备，其流程与通常的写流程不同。Broiler 在 virtio-blk 初始化过程中，通过 KVM_IOEVENTFD IOCTL 向 KVM 维护的 ioevetfd 链表里注册一个监听函数，当前端设备对 kick 寄存器写操作会导致虚拟机会 VM-EXIT，此时 KVM 捕获到的退出原因是 EXIT_REASON_IO_INSTRUCTION, 那么 KVM 调用 handle_io() 函数进行 IO 模拟，与普通的写 IO 模拟不同的是 kernel_pio() 函数会被调用，该函数在 KVM 的 PIO Bus 上查找 Kick 寄存器的监听函数，当找到监听函数，那么 KVM 通过 IOEVENT 机制通知 Broiler 的 virtio_pci_ioevent_callback() 函数，该函数调用 notify_vq() 函数会唤醒 virtio-blk 的线程处理磁盘的 IO 请求，在处理的过程中后端设备就会从 virtio-blk 的 Virtqueue 中读取 IO 请求的描述信息，并更新 last_avail_idx，然后通过 Desc-Ring 的描述处理 IO 请求。当 IO 请求模拟完之后 Broiler 调用 virtio_blk_complete() 函数更新 virtio-queue Used-Ring 的 used_idx 值，并向虚拟机注入中断，虚拟机在次运行并收到中断之后，virtio-blk 前端设备消费该中断，然后读取 Used-ring 并更新 last_used_idx 和 used_idx 的值，最终确认 virtio-blk 的请求完成.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-----------------------------------------------------

###### <span id="F4">virtio-blk Virtqueue</span>

![](/assets/PDB/HK/TH001728.png)

Virtqueue 是 virtio-blk 的前端设备和后端设备交互的核心组件，其由三个环形队列构成，分别为 Desc-Ring、Avail-Ring 和 Used-Ring, Desc-Ring 用于描述前端 IO 请求相关，其中包含了 IO 请求数据在 Guest OS 内部的地址、长度和 IO flags; Avail-Ring 用于描述前端设备新的 IO 请求，每当前端设备准备好 IO 请求之后更新完 Desc-Ring，然后将对于的 Desc-idx 填入到 Avail-Ring\[avail_idx] 内，接着更新 avail_idx, 一切处理完毕之后向 Virtqueue PCI BAR0 的 Kick 寄存器执行写操作，以此告诉后端 IO 请求准备完毕。Kick 寄存器的写会导致 VM-EXIT，执行权回到了 KVM，KVM 利用 ioeventfd 机制将请求直接发送给 Broiler，Broiler 获得执行权之后唤醒后端设备进行 IO 模拟。后端设备发现 Avail-Ring 中由新的 IO 请求，于是从 Avail-Ring 中获得最新请求在 Desc-Ring 中的索引，然后解析 Desc-Ring 中指定的 Entry，并获得 IO 请求相关的 GPA 地址、长度以及请求标志，后端设备利用这些数据将 GPA 地址转换成 HPA 地址，然后进行 IO 模拟，IO 模拟处理完毕之后，后端设备将 Desc-Ring 处理完的 IO 请求对应的 Desc-idx 写入到 Used-Ring\[used_idx] 项里并更新 used_idx 值，后端设备最后在虚拟机重新 VM_ENTRY 之前注入中断。虚拟机重新运行之后，virtio-blk 收到了中断，然后发现 Used-Ring 中有更新，于是读取 Used-Ring[used_idx] 的内容，并在 Desc-Ring 队列中找到 IO 请求的描述，那么对应的 IO 请求处理完毕，以上便是基于 virtqueue 的前后端设备交互流程.

![](/assets/PDB/HK/TH001738.png)

Virtqueue 的内存布局如上，其由前端设备在 Guest OS 内分配一块内存，然后根据 virtio 协议前后端达成一致的内存布局，前端设备在初始化 virtio-blk 阶段通过 BAR0 相关寄存器与后端设备进行协商 virtqueue 的信息，其中包括 virtqueue 的 GPA 地址、长度以及设备目前使用那个 virtqueue. 在 Virtqueue 的内存布局中，Desc-Ring 占用了最前端部分，其包含了 VIRTIO_BLK_QUEUE_SIZE 个成员，每个成员用于记录一次前端设备 IO 请求描述，包括 IO 请求数据的地址、长度以及标志; Virtqueue 的第二大部分是紧随其后的 Avail-Ring，其也包含了 VIRTIO_BLK_QUEUE_SIZE 个成员，每个成员描述一个新的 IO 请求在 Desc-Ring 中的位置. 在 Desc-Ring 与 Avail-Ring 之间存在两个变量，分别是 avail_flags 和 avail_idx; Virtqueue 的第三部分是 Used-Ring，Used-Ring 并没有紧随 Avail-Ring 之后，而是在下一个 PAGE_ALIGN 的地方开始，那么 Avail-Ring 和 Used-Ring 之间存在一段空洞 pad\[]. Used-Ring 同样包含了 VIRTIO_BLK_QUEUE_SIZE 个成员，并且 Used-Ring 前面紧贴着两个变量，分别是 used_idx 和 used_flags, Used-Ring 之后也紧贴着 avail_event_idx.

![](/assets/PDB/HK/TH001739.png)

Virtio-blk 前端设备的 BAR0 的多个域包含了 virtqueue 相对配置，其中 \[0x4, 0x7] 域描述了 virtqueue 在 Guest OS 内的地址，即 GPA 地址; \[0x0C, 0x0D] 域描述了 virtqueue 中每个 Ring 中成员的数量, Broiler virtqueue 支持 VIRTIO_BLK_QUEUE_SIZE 个成员; \[0x0E, 0x0F] 域用于描述当前使用第几个 virtqueue，在支持多 virtqueue 的设备，该域可以设置设备当前使用哪个 virtqueue，对于单 virtqueue 的设备，那么该域为 0; \[0x014, 0x15] 域用于描述 virtqueu 使用的中断信息.

![](/assets/PDB/HK/TH001741.png)

Virtqueue 的 Avail-Ring 是一个无锁的 FIFO 环形队列，avail_idx 变量对前后端可见，但只有前端可以对其进行读写操作，后端只能对其进行读操作，avail_idx 用于描述最新的 IO 请求在 Avail-Ring 中的索引。后端设备维护 last_avail_idx 变量，用于描述上一次 IO 请求的索引。当前端没有新的 IO 请求，avail_idx 和 last_avail_idx 是相等的; 当前端设备有新的 IO 请求，那么前端设备会更新 avail_idx 并通过 kick 通知后端去处理新的 IO 请求; 后端收到通知之后，检查 last_avail_idx 和 avail_idx 是否相等，如果发现 avail_idx 更大，那么表示 Avail-Ring 中有新的 IO 请求需要处理，那么后端设备开始处理 IO 请求并更新 last_avail_idx，使其与 avail_idx 相同. 由于前后端设备各自维护一个变量，因此不需要锁进行处理，所以可以做到无锁交互.

![](/assets/PDB/HK/TH001742.png)

Virtqueue 的 Used-Ring 也是一个无锁 FIFO 环形队列, used_idx 变量对前后端设备可见，但只有后端设备可以对其读写操作，前端设备只能对其读操作，used_idx 用于描述已经完成的 IO 请求在 Used-Ring 中的索引。前端设备维护 last_used_idx 变量，用于描述上一次完成的 IO 请求的索引。当后端设备没有新完成 IO 请求，那么 used_idx 与 last_used_idx 是相等的; 当后端设备处理完一个 IO 请求之后，那么后端设备会更新 used_idx 并在虚拟机再次运行的时候注入中断，以此告诉前端设备有新的 IO 请求处理完成; 当前端设备收到指定中断之后，前端设备检查 last_used_idx 与 used_idx 是否相同，如果 used_idx 更大，那么说明有新的 IO 请求完成，前端设备就更新 last_used_idx 的值，使其与 used_idx 相同，最后 IO 请求处理完毕。由于前后端设备维护各自的一个变量，因此不需要进行锁操作，所以可以做到 Used-Ring 的无锁.

![](/assets/PDB/HK/TH001729.png)

当 Guest OS 内部前端设备 FE 需要与后端设备写数据时，那么前端设备会将数据准备好，然后调用 virtqueue_push() 函数将数据所在的 GPA 地址和长度信息填充到 Desc-Ring, 这个时候获得填充内容在 Desc-Ring 中的索引 desc-idx，紧接着前端设备先更新 Avail-Ring 的 avai_idx, 然后将 desc-idx 更新到 Avail-Ring\[avail_idx] 对应的 Entry 里，最后通过向 virtio-blk 对应的 BAR0 的 kick 寄存器写操作，那么这个时候 Guest 会 VM_EXIT。KVM 收到 VM_EXIT 的 reason 为 EXIT_MMIO, 那么通过 eventfd 机制将这个消息通知给 Broiler，Broiler 收到这个信息之后将消息通过 EPOLL 广播出去，这个时候后端设备模拟 BAR0 的 kick 寄存器的处理函数收到这个信息之后，通过 eventfd 告诉后端设备前端有数据到达。后端设备首先从 Avail-Ring 中获得 avail-idx 的值，然后与后端设备维护的 last_avail_idx 进行比较，如果发现 last_avail_idx 小于 avail-idx, 那么表示 Avail-Ring 里有前端设备新下发的数据需要读取，那么后端设备通过 Get_buf() 函数获得 Avail-Ring 中 Desc-idx 的值，然后从 Desc_Ring\[Desc-idx] 中获得数据所在的 GPA 和长度信息，接下来后端设备将 GPA 转换成 HVA，并搬运数据, 搬运完毕之后后端设备更新 last_avail_ring.

![](/assets/PDB/HK/TH001730.png)

当后端设备更新完 Avail-Ring 之后与前端的交互并还没有完成，这个时候需要告诉前端设备后端已经更新完毕，那么后端设备更新 Used-Ring 的 used_idx，并将前端设备写请求在 Desc-Ring 中的 Desc-idx 写入到 Used-Ring\[used_idx] 里，这个时候后端设备向 virtio-blk 对应的 PCI 设备注入中断，虚拟机运行之后收到 virtio-blk PCI 设备的中断，那么前端设备会将自己维护的 last_used_idx 和 Used-Ring 的 used_idx 进行比较，如果 last_used_idx 小于 used_idx, 那么表示 Used-Ring 里有未处理的数据，那么前端设备更新 last_used_idx, 然后读出 Used-Ring\[used_idx] 的值，该值是 Desc-Ring 里面的一个 Desc-idx 索引，然后读出 Desc-Ring\[Desc-idx] 的值，这个时候前端设备发现是之前 Request，那么前端设备认为前一次 Request 完成. 至此一次完整的前后端数据交互完成。另外值得注意的是在 virtio-blk 磁盘设备里，只有前端设备可以写 Avail-Ring，而后端设备只能写 Used-Ring，那么请求只能前端设备发出，后端设备只能处理请求.

![](/assets/PDB/HK/TH001740.png)

virtio-blk 磁盘前后端 IO 请求调用栈如上图，当前端设备有新的 IO 请求，那么前端设备调用 virtio_add_req() 函数向 virtqueue 的 Desc-Ring 和 Avail-Ring 中更新 IO 请求，并更新 avail_idx，接着调用 virtqueue_notify() 函数向 virtio-blk BAR0 的 kick 寄存器执行写操作，以此告诉后端设备有新的 IO 请求, 该操作会导致 VM-EXIT。KVM 获得控制权之后发现 VM 退出的原因是 EXIT_REASON_IO_INSTRUCTION, 并且是因为 OUT 指令退出，那么 KVM 经过函数调用进入 kernel_pio() 函数，该函数会在 KVM 维护的 PIO_BUS 上查找 BAR0 kick 寄存器注册的 IOEVENTFD 监听函数，当查找到 KVM 会调用 kvm_iodevice_write() 函数通过 IOEVENTFD 机制直接通知用户空间的 Broiler，Broiler 收到通知之后获得执行权，并直接调用 virtio_pci_ioevent_callback() 函数，该函数会直接唤醒磁盘线程的处理函数 virtio_blk_do_io(), 后端设备此时会检查 Avail-Ring 是否有新的 IO 请求，此时会拿后端设备维护的 last_avail_idx 和 avail_idx 进行比较，如果 avail_idx 大于 last_avail_idx，那么表示有新的 IO 请求，那么后端设备开始处理 IO 请求，并更新 last_avail_idx 和 avail_idx。当 IO 请求处理完毕之后，后端设备会向 Used-Ring 中写入一个新的项，新项指向与 Avail-Ring 指向同一个 Desc-Ring Entry，接着更新 used_idx，最后后端设备会通知 KVM 在虚拟机 VM_ENTRY 时注入一个 MSI 中断告诉前端设备 IO 请求已经处理完毕，KVM 收到通知注入中断并再次运行虚拟机，此时前端收到 MSI 中断，然后调用 virtblk_done() 函数，并在其子函数中检查 last_used_idx 是否与 used_idx 相等，如果 used_idx 更大那么说明有 IO 请求已经处理完毕，那么这个时候从 Used-Ring 处理完成的 IO 请求，那么一个 IO 请求处理完毕.

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-----------------------------------------------

###### <span id="F7">virtio-blk 初始化</span>

![](/assets/PDB/HK/TH001743.png)

virtio 协议规定 virtio 设备初始化流程如上，第一步是重置设备

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

-------------------------------------------

<span id="E"></span>

![](/assets/PDB/BiscuitOS/kernel/IND00000I.jpg)

#### 中断虚拟化

![](/assets/PDB/HK/TH001754.png)

在计算机架构中，CPU 运行的速度远远大于外设运行的速度，在早期程序设计时，计算机如果要获得外部设备完成 IO 情况，计算机就不得不通过轮询来查询外设完成情况，因此往往做了很多无用的外设，从而导致计算机性能低下。为了解决这个问题引入了中断机制，**中断** 是为了解决外部设备完成某些工作之后通知 CPU 的一种机制，中断大大解放了 CPU, IO 操作效率大增. 在 X86 架构中，中断是一种电信号，由硬件外设产生，并直接送入中断控制器的输入引脚，然后由中断控制器下处理器发送相应的信号。处理器一旦检查到该信号，便会中断当前处理的工作转而处理中断。

![](/assets/PDB/HK/TH001755.png)

X86 架构的 CPU 为中断提供了两条外接引脚: **NMI** 和 **INTR**. 其中 NMI 是不可屏蔽中断，通常用于电源掉电和物理存储器奇偶校验; INTR 是可屏蔽中断，可以通过设置中断屏蔽位来进行中断屏蔽，主要用于接受外部硬件的中断信号，这些信号由中断控制器传递给 CPU。常见的中断控制器由两种: 8259A PIC 和 APIC.

###### <span id="E0">PIC 8259A</span>

![](/assets/PDB/HK/TH001756.png)

X86 架构中，传统的 PIC(Programmable Interrupt Controller) 可编程中断控制器由两片 8259A 外部芯片以级联的方式连接在一起，每个芯片可处理多达 8 个不同的 IRQ，Slave PIC 的 INT 输出线连接到 Master PIC 的 IRQ2 引脚，所以可用的 IRQ 线的个数达到 15 个. 中断引脚具有优先级，其中 IR0 优先级最高，IR7 优先级最低。PIC 内部具有三个重要的寄存器:

![](/assets/PDB/HK/TH001757.png)

**IRR**(Interrupt Request Register) 中断请求寄存器, 一共 8 bit 对应 IR0 ~ IR7 8 个中断引脚. 某位置位代表收到对应引脚收到中断但还没有提交给 CPU. **ISR**(In Service Register) 服务中寄存器，一共 8 bit，某位置位代表对应引脚的中断已提交给 CPU 处理，但 CPU 还没有处理完. **IMR**(Interrupt Mask Register) 中断屏蔽寄存器，一个 8 bit，某位置位代表对应的引脚被屏蔽. 除此之外，PIC 还有一个 EOI 位，当 CPU 处理完一个中断时，通过写该 bit 告知 PIC 中断处理完毕。PIC 向 CPU 递交中断的流程如下:

1. 一个或多个 IR 引脚产生电平信号，若中断对应的 IRR bit 没有置位.
2. PIC 拉高 INT 引脚通知 CPU 中断发生
3. CPU 通过 INTA 引脚应答 PIC 表示中断请求收到
4. PIC 收到 INTA 应答之后，将 IRR 中具有高优先级的位清零，并置位 ISR 对应位
5. CPU 通过 INTA 引脚第二次发出脉冲，PIC 将最高优先级 Vector 送到数据线上.
6. 等待 CPU 写 EOI.
7. 收到 EIO 后，ISR 中最高优先级位清零.

---------------------------------------------------

###### <span id="E1">APIC: Local APIC and I/O APIC</span>

![](/assets/PDB/HK/TH001758.png)

PIC 可以在 UP(单处理器)平台上工作，但无法用于 MP(多处理)平台，为此 **APIC**(Advanced Programmable Interrupt Controller) 因运而生。APIC 由位于 CPU 中的本地高级可编程中断控制器 **LAPIC**(Local Advanced Programmable Interrupt Controller) 和位于主板南桥中 I/O 高级可编程中断控制器 **I/O APIC**(I/O Advanced Programmable Interrupt Controller) 两部分构成，他们的关系如上图.

![](/assets/PDB/HK/TH001759.png)

每个 Logical Processor 逻辑处理器都有自己的 Local APIC，每个 local APIC 包含了一组 Local APIC 寄存器，用于控制 kicak 和 external 中断的产生、发送和接受等，也用于产生和发送 IPI。Local APIC 寄存器组以 MMIO 形式映射到系统的存储域空间，因此可以像操作物理内存一样访问。Local APIC 寄存器在存储域的起始物理地址为 0xFEE0000; 在 x2APIC 模式的 Local APIC 寄存器映射到 MSR 寄存器组来代替，因此可以使用 RDMSR 和 WRMSR 指令来访问 Local APIC 寄存器。

![](/assets/PDB/HK/TH001760.png)

Local APIC 由一组 LVT(Local vector table) 寄存器用来产生和接口 Local interrupt source. 由 LVT 的 LINT0 和 LINT1 寄存器对应着处理器 LINT0 和 LINT1 Pin, 它们可以直接接受外部 I/O 设备或连接 8259A 兼容类的外部中断控制器. 典型的 LINT0 作为处理器的 INTR Pin 接着外部的 8259 类的中断控制器的 INTR 输出端，LINT1 作为处理器的 NMI Pin 接外部设备的 NMI 请求.

![](/assets/PDB/HK/TH001761.png)

IO APIC 通常有 24 个不具有优先级的引脚用于连接外部设备，当收到某个引脚的中断信号之后，IO APIC 根据软件设定的 PRT(Programmable Redirection Table) 表查找对应引脚的 RTE(Redirection Table Entry). 通过 PTE 的各个字段，格式化出一条包含该中断所有信息的中断信息，再由系统总线发送给特定的 CPU 的 Local APIC，Local APIC 收到该信息之后择机将中断递交给 CPU 处理. IO APIC 也有自己的寄存器，同样也是通过 MMIO 映射到存储域空间。在 APIC 系统中，中断发起大致流程如下:

1. IO APIC 收到某个引脚产生的中断信号
2. 查找 PRT 表获得引脚对应的 RTE
3. 根据 RTE 个字段格式化出一条中断信息，并确定发送给哪个 CPU 的 LAPIC
4. 通过系统总线发送中断信息
5. Local APIC 收到中断信息，判断是否由自己接受
6. Local APIC 确认接受，将 IRR 中对应的位置位，同时确认是否由 CPU 处理
7. 确认由 CPU 处理中断，从 IRR 中获得最高优先级中断，将 ISR 中对应的位置位，提交中断。对于边缘触发的中断，IRR 中对应的位此时清零.
8. CPU 处理完中断，软件写 EOI 寄存器告知中断处理完成. 对于电平触发中断，IRR 中对应的位清零. Local APIC 提交下一个中断.

在 MP(多处理器) 平台上，多个 CPU 要协同工作，处理器间中断 (Inter-processor Interrupt, **IPI**) 提供 CPU 之间相互通信的手段。CPU 可以通过 Local APIC 的 ICR(Interrupt Command Register, 中断命令寄存器) 向指定的一个/多个 CPU 发送中断. OS 通常使用 IPI 来完成诸如进程转移、中断平衡和 TLB 刷新等任务.

--------------------------------------------- 

###### <span id="E2">中断重要概念</span>

![](/assets/PDB/HK/TH001763.png)

中断可分为**同步中断**(Synchronous Interrupt) 和**异步中断**(Asynchronous Interrupt)。同步中断是当指令执行时由 CPU 控制单元产生，之所以称为同步，是因为只有在一条指令执行完毕后 CPU 才会发出中断，发生中断之后 CPU 立即处理，而不是发生在代码指令执行期间，比如系统调用; 异步中断是指由其他硬件设备依照 CPU 时钟信号随机产生，即意味着中断能够在指令之间发生，中断产生之后不能立即被 CPU 执行.

![](/assets/PDB/HK/TH001762.png)

在 Intel X86 架构中，同步中断称为**异常**(exception), 异步中断称为**中断**(Interrupt), 中断可以分为**可屏蔽中断**(Maskable Interrupt) 和**不可屏蔽中断**(Nomaskable Interrupt). 异常可分为: **故障**(Fault)、**陷阱**(Trap)和**终止**(abort)三类. 在 X86 架构中每个中断被赋予一个唯一的编号或者向量**Vector**(8 位无符号整数).

![](/assets/PDB/HK/TH001764.png)

在 X86 架构保护模式下，系统使用**中断描述表**(Interrupt Descriptor Table, IDT) 表示中断向量表，总共 256 个描述符，IDT 的索引称为中断向量 Vector. IDT 表实际就是一个大数组，IDTR 寄存器指明了 IDT 在物理内存的位置以及长度，用于存放各种门(中断门、陷阱门、任务门)，这些门是中断和异常通往各自处理函数的入口。

###### PIN/IRQ/GSI/VECTOR

PIN、IRQ、GSI 和 Vector 这几个概念容易搅浑，**IRQ** 是 PIC 时代的产物，由于 ISA 设备通常是连接到固定的 PIC 引脚，所以说一个设备的 IRQ 实际就是指它连接的 PIC 引脚号。IRQ 暗示着中断优先级，例如 IRQ0 比 IRQ1 有着更高的优先级。当进入到 APIC 时代，为了向前兼容，习惯用 IRQ 表示一个设备的中断号，但对于 16 以下的 IRQ，可能不再与 IOAPIC 的引脚对应. **Pin** 是引脚号，表示 IOAPIC 的引脚，PIC 时代类似的是 IRQ。Pin 的最大值受 IOAPIC 的引脚数限制，目前取值范围是 \[0, 23]. **GSI**(Global System Interrupt) 是 APIC 时代引入的概念，它为系统中的每个中断源指定唯一的中断号.

![](/assets/PDB/HK/TH001765.png)

上图中有 3 个 I/O APIC, IO-APIC0 具有 24 个引脚，其中 GSI Base 为 0, 每个 Pin 的 **GSI=GSI_Base + Pin** , 故 IO-APIC0 的 GSI 范围为 \[0: 23]. IO-APIC1 具有 16 个引脚，GSI base 为 24，GSI 范围为 \[24, 39], 以此类推。APIC 要求 ISA 的 16 个 IRQ 应该被 Identify map 到 GSI \[0, 15]. **Vector** 是中断中 IDT 表中的索引，是一个 CPU 概念，每个 IRQ (或 GSI) 都对应一个 Vector。在 PIC 模式下，IRQ 对应的 **vector = Start_Vector + IRQ**; 在 APIC 模式下, IRQ/GSI 的 vector 由操作系统分配.

##### 操作系统对中断/异常的处理流程

虽然各种操作系统对中断/异常处理的实现不同，但基本流程遵循如下顺序:
一个中断或异常发生，打断当前正在执行的任务

1. CPU 通过 vector 索引 IDT 表得到对应的门，并获得其处理函数的入口地址
2. 保存被打断任务的上下文，并跳转到中断处理函数进行执行
3. 如果是中断，处理完成后需要写 EOI 寄存器应答，异常不需要
4. 恢复被打断任务的上下文，准备返回
5. 从中断/异常的处理函数返回，恢复被打断的任务，使其继续执行

![](/assets/PDB/BiscuitOS/kernel/IND000100.png)

---------------------------------

#### <span id="E3">X86 中断虚拟化</span>

![](/assets/PDB/HK/TH001766.png)

在虚拟化场景中，VMM 也需要为 Guest OS 展现一个与物理中断架构类似的虚拟中断架构。如上图展示虚拟机的中断架构，和物理平台一样，每个 VCPU 都对应一个虚拟 Local APIC 用于接收中断. 虚拟平台也包含了虚拟 I/O APIC 或者虚拟 PIC 用于发送中断。和 VCPU 一样，虚拟 Local APIC、虚拟 I/O APIC 和 虚拟 PIC 都是由 VMM 维护. 当虚拟设备需要发送中断时，虚拟设备会调用虚拟 I/O APIC 的接口发送中断，虚拟 I/O APIC 根据中断请求，挑选出相应的虚拟 Local APIC, 调用其接口发出中断请求，虚拟 Local APIC 进一步利用 VT-x 的事件注入机制将中断注入到相应的 VCPU. 由此可见中断虚拟化主要任务就是实现虚拟 PIC、虚拟 I/O APIC 和虚拟 Local APIC，并且实现虚拟中断的生成、采集和注入的过程。

###### 虚拟 PIC

![](/assets/PDB/HK/TH001757.png)

虚拟 PIC 本质上是一个虚拟设备，因此可以放在用户空间侧模拟(QEMU/Broiler)，也可以放在内核侧 KVM 来模拟。根据 PIC 硬件规范，在软件上模拟出虚拟 PIC 与物理 PIC 一样的接口。PIC 主要为软件提供了以下几个接口用于操作 PIC:

* 4 个初始化命令字(Initialization Command Words): ICW1/ICW2/ICW3/ICW4
* 3 个操作命令字(Operation Command Words): OCW1/OCW2/OCW3

在 X86 平台上，PIC 的 ICW1/ICW2/ICW3/ICW4 和 OCW1/OCW2/OCW3 都是 I/O 端口访问，因可以使用 IO 端口模拟即可，具体而言这些接口通过 I/O 端口 0x20/0x21 以及 0xA0/0xA1 来访问，VMM 可以设置 VMCS 的 I/O bitmap 中相应的位，使得 Guest OS 可以访问这些端口时发生 VM-Exit, 以便 VMM 截获.

![](/assets/PDB/HK/TH001767.png)

虚拟 PIC 的创建过程如上图，QEMU/Broiler HpyV 程序通过 ioctl 接口将 KVM_CREATE_IRQCHIP 命令传递给 KVM，KVM 通过调用 kvm_pic_init() 函数在内核空间虚拟两个 8259A 设备，一个作为主 PIC，另外一个作为从 PIC，虚拟 PIC 一共向系统注册 0x20/0xa0/0x4d0 三个端口，端口通过 kvm_io_bus_register_dev() 函数进行注册，因此只要 Guest OS 访问三个 IO 端口都会导致虚拟机 VM-Exit. 另外通过 kvm_iodevice_init() 函数为三个端口设置 IO 端口模拟的函数，IO 端口读模拟最终通过 picdev_read() 函数实现，而 IO 端口写模拟最终通过 picdev_write() 函数实现.

![](/assets/PDB/HK/TH001768.png)

从虚拟机内部看到系统 IO 空间中，主 PIC 映射到端口 0x20-0x21，从 PIC 映射到端口 0xa0-0xa1. 接下来在 Broiler 虚拟一个设备，其包含一个异步 IO，对该 IO 进行读操作会出发一个中断(源码位置: foodstuff/Broiler-interrup-vPIC.c)

![](/assets/PDB/HK/TH001769.png)

Broiler 模拟了一个设备，该设备包含了一段 IO 端口，其范围是 \[0x6020, 0x6030], 里面包含了两个寄存器，第一个寄存器 IRQ_NUM_REG 用于获得设置使用的 IRQ，第二个寄存器是一个异步 IO，对该寄存器进行写操作会触发中断。Broiler 在 69 行分配一个 IRQ 号，然后调用 broiler_irq_line() 函数将 IRQ 后注册到 KVM 模拟的 vPIC 里进行管理。Broiler 在 72-102 行实现一个异步 IO, 如果 Guest OS 对该 IO 端口进行写操作，那么会唤醒 irq_threads 线程，线程的作用是向 Guest OS 注入一个 IRQ 中断，可以看到 45 行调用 broiler_irq_line() 函数拉高电平以便模拟高电平，进而产生中断，此时 KVM 会收到 ioctl 命令 KVM_IRQ_LINE, 然后 KVM 向 Guest OS 注入中断. 那么有了 Broiler 侧的模拟设备，接下来就是 Guest OS 内部驱动来处理中断，BiscuitOS 已经支持该驱动程序的部署，其部署逻辑如下:

{% highlight bash %}
# 切换到 BiscuitOS 目录
cd BiscuitOS
make linux-5.10-x86_64_defconfig
make menuconfig

  [*] Package --->
      [*] KVM --->
          [*] vInterrupt: Broiler vPIC interrupt

# 保存配置并使配置生效
make

# 进入 Broiler 目录
cd output/linux-5.10-x86_64/package/Broiler-vPIC-interrupt-default/
# 下载源码
make download
# 编译并运行源码
make build
# Broiler 打包
cd output/linux-5.10-x86_64/package/BiscuitOS-Broiler-default/
make build
{% endhighlight %}

![](/assets/PDB/HK/TH001747.png)
![](/assets/PDB/HK/TH001770.png)
![](/assets/PDB/HK/TH001771.png)
![](/assets/PDB/HK/TH001772.png)

> [Broiler-vPIC-interrupt-default Gitee @link](https://gitee.com/BiscuitOS_team/HardStack/tree/Gitee/Virtualization/vInterrupt/Broiler-vPIC-interrupt)

Guest OS 驱动源码比较简单，首先通过 request_resource() 向 IO 空间注册了设备的 IO 端口，其 IO 端口域为 \[0x6020, 0x6030], 驱动接着调用 ioport_map() 函数将 IO 端口映射到虚拟内存，接着在 52 行从设备的 0x6024 端口获得设备使用的中断号，接着对中断号进行注册并使用 Broiler_irq_handler() 函数作为中断处理函数，最后驱动向端口 0x6020 进行写操作，那么这会触发设备向 CPU 发送一个中断，接下来在 BiscuitOS 实践该案例:

![](/assets/PDB/HK/TH001773.png)

Broiler 启动 BiscuitOS 系统之后，加载驱动 Broiler-vPIC-interrupt-default.ko, 可以看到驱动加载成功，等待 5s 之后中断处理程序收到设备发来的中断，此时可以看到 IRQ 为 6，接着查看 IO 空间，可以看到端口 0x6020-0x6030 分配给 "Broiler PIO vPIC" 使用，实践符合预期，那么接下来分析一下 Broiler 如何与 KVM 配合模拟并向 Guest OS 注入中断的.

![](/assets/PDB/HK/TH001774.png)

Broiler 中模拟设备如果需要使用 vPIC 的中断，那么可以调用 irq_alloc_line() 分配一个函数，然后调用 broiler_irq_line() 函数向 KVM 的虚拟 PIC 注册一个中断，其核心通过 ioctl 向 KVM 传入 KVM_IRQ_LINE 命令以及新分配的中断号. KVM 的 kvm_vm_ioctl() 函数负责消费 Broiler 传递的 KVM_IRQ_LINE 命令以及新分配的中断号，此时 KVM 调用 kvm_vm_ioctl_irq_line() 函数将该中断与主





